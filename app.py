#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FastAPI Webåº”ç”¨ï¼šAIæ–‡æ¡£ç”Ÿæˆå™¨
é›†æˆèŠå¤©ç•Œé¢å’Œæ–‡æ¡£ç”ŸæˆåŠŸèƒ½
"""

import os
import json
import logging
import uuid
from datetime import datetime
from typing import Dict, Any, List, Optional
from pathlib import Path

from fastapi import FastAPI, HTTPException, UploadFile, File, Form, Body
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, FileResponse, JSONResponse
from starlette.requests import Request
from pydantic import BaseModel
from docx import Document

# å¯¼å…¥ç°æœ‰çš„AIæ–‡æ¡£ç”Ÿæˆå™¨
from main import AIDocGenerator

# Load environment variables
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# --- FastAPI App Setup ---
app = FastAPI(title="AIæ–‡æ¡£ç”Ÿæˆå™¨", description="æ™ºèƒ½æ–‡æ¡£ç”Ÿæˆå¹³å°")
app.mount("/static", StaticFiles(directory="frontend/static"), name="static")
templates = Jinja2Templates(directory="frontend/templates")

# --- Data Models ---
class DocumentItem:
    def __init__(self, name: str, doc_id: str):
        self.id = doc_id
        self.name = name
        self.status = "å¾…å¤„ç†"  # "å¾…å¤„ç†", "å·²å®Œæˆ", "ç”Ÿæˆå¤±è´¥"
        self.filled_document_path: Optional[str] = None
        self.error_info: Optional[str] = None
        self.matched_template_path: Optional[str] = None

class ChatSession:
    def __init__(self, session_id: str):
        self.session_id = session_id
        # Key: doc_id, Value: DocumentItem object
        self.document_items: Dict[str, DocumentItem] = {}
        # Key: template_name, Value: template_path
        self.templates: Dict[str, str] = {}
        # Key: file_name, Value: file_path
        self.context_files: Dict[str, str] = {}
    
    def get_dashboard_data(self) -> List[Dict]:
        """è·å–ç”¨äºå‰ç«¯å±•ç¤ºçš„æ–‡æ¡£æ¸…å•æ•°æ®"""
        items_data = []
        for item in self.document_items.values():
            item_data = item.__dict__.copy()
            item_data['template_status'] = "å·²åŒ¹é…" if item.matched_template_path else "æœªåŒ¹é…"
            items_data.append(item_data)
        return sorted(items_data, key=lambda x: x['name'])

class ChatRequest(BaseModel):
    session_id: str
    message: str
    action: Optional[str] = None
    data: Optional[Dict[str, Any]] = None
    message_id: Optional[str] = None

# å…¨å±€å˜é‡å­˜å‚¨ä¼šè¯æ•°æ®
sessions: Dict[str, ChatSession] = {}
ai_generator = AIDocGenerator(api_key=os.environ.get("OPENROUTER_API_KEY", ""))

# --- Helper Functions ---
def get_or_create_session(session_id: str) -> ChatSession:
    if session_id not in sessions:
        logger.info(f"âœ¨ Creating new session: {session_id}")
        sessions[session_id] = ChatSession(session_id)
    return sessions[session_id]

def get_session_upload_dir(session_id: str) -> Path:
    """Gets and creates the upload directory for a session."""
    upload_dir = Path("uploads") / session_id
    upload_dir.mkdir(parents=True, exist_ok=True)
    return upload_dir

# --- API Endpoints ---
@app.get("/", response_class=HTMLResponse)
async def main_page(request: Request):
    """ä¸»é¡µé¢"""
    return templates.TemplateResponse("index.html", {"request": request})

@app.get("/api/templates", response_model=List[Dict[str, str]])
async def get_templates():
    """è·å–å¯ç”¨çš„æ–‡æ¡£æ¨¡æ¿åˆ—è¡¨"""
    templates_list = []
    template_dir = Path("templates")
    template_dir.mkdir(exist_ok=True)

    # Add docx and doc files from the default 'templates' directory
    for ext in ["*.docx", "*.doc"]:
        for f in template_dir.glob(ext):
            templates_list.append({"name": f.name, "path": str(f)})
            
    if not templates_list:
        # To prevent errors on a clean setup, provide a placeholder
        return [{"name": "æ— å¯ç”¨æ¨¡æ¿", "path": ""}]
        
    return templates_list

@app.post("/api/generate")
async def generate_document_handler(
    session_id: str = Form(...),
    doc_id: str = Form(...),
    template_path: str = Form(...),
    json_data: str = Form(...),
    additional_docs: List[UploadFile] = File([])
):
    """
    Handles the primary document generation request with multimodal input.
    """
    session = get_or_create_session(session_id)
    doc_item = session.document_items.get(doc_id)
    if not doc_item:
        raise HTTPException(status_code=404, detail="Document item not found.")

    upload_dir = get_session_upload_dir(session_id)
    attachment_paths = []
    direct_json = None
    
    # --- Workflow Logic ---
    # Prioritize attachments over direct JSON input. This feels more intuitive for the user.
    # If files are uploaded, they are the source of truth for generation.

    # 1. Save any uploaded context files
    for file in additional_docs:
        file_path = upload_dir / f"context_{uuid.uuid4().hex[:8]}_{file.filename}"
        with open(file_path, "wb") as buffer:
            buffer.write(await file.read())
        attachment_paths.append(str(file_path))
        logger.info(f"ğŸ’¾ Saved context file for generation: {file_path}")

    # 2. Decide on the data source
    if not attachment_paths:
        # No attachments, so try to use the JSON data from the textarea
        logger.info("No attachments provided. Checking for direct JSON input.")
        if json_data and json_data.strip() and json_data.strip() != "{}":
            try:
                direct_json = json.loads(json_data)
                logger.info("âœ… Using valid JSON data provided by user.")
            except json.JSONDecodeError:
                logger.error("âš ï¸ Invalid JSON provided by user and no attachments. Generation will fail.", exc_info=True)
                raise HTTPException(status_code=400, detail="Provided JSON is invalid and no context files were uploaded.")
        else:
            # No data source at all
            logger.error("âŒ No data source provided. User sent neither files nor JSON.")
            raise HTTPException(status_code=400, detail="You must upload context documents or provide JSON data to generate a document.")
    else:
        # Attachments are present, they will be used as the primary source.
        logger.info(f"âœ… Attachments found ({len(attachment_paths)} files). They will be used for AI data extraction.")


    output_dir = Path("generated_docs")
    output_dir.mkdir(exist_ok=True)
    # Sanitize the doc_item.name for the filename
    safe_name = "".join(c for c in doc_item.name if c.isalnum() or c in (' ', '_')).rstrip()
    output_path = output_dir / f"{safe_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.docx"

    try:
        success = ai_generator.run_generation(
            doc_template_path=template_path,
            output_path=str(output_path),
            attachment_paths=attachment_paths, # Will be empty if direct_json is used
            direct_json_data=direct_json      # Will be None if attachments are used
        )

        if success:
            doc_item.status = "å·²å®Œæˆ"
            doc_item.filled_document_path = str(output_path)
            response_message = f"âœ… æ–‡æ¡£ '{doc_item.name}' å·²æˆåŠŸç”Ÿæˆï¼"
        else:
            doc_item.status = "ç”Ÿæˆå¤±è´¥"
            doc_item.error_info = "AIç”Ÿæˆè¿‡ç¨‹å‡ºé”™æˆ–æœªèƒ½è¿”å›æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚"
            response_message = f"âŒ ç”Ÿæˆæ–‡æ¡£ '{doc_item.name}' å¤±è´¥ã€‚"
    
    except Exception as e:
        logger.error(f"Error during document generation for '{doc_item.name}': {e}", exc_info=True)
        doc_item.status = "ç”Ÿæˆå¤±è´¥"
        doc_item.error_info = str(e)
        response_message = f"âŒ ç”Ÿæˆæ–‡æ¡£ '{doc_item.name}' æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯ã€‚"
    
    finally:
        # Clean up temporary context files
        for path in attachment_paths:
            try:
                os.remove(path)
                logger.info(f"ğŸ—‘ï¸ Removed temp context file: {path}")
            except OSError as e:
                logger.error(f"Error removing temp file {path}: {e}")

    return JSONResponse({
        "message": response_message,
        "dashboard": session.get_dashboard_data()
    })

@app.post("/api/chat/message")
async def chat_handler(req: ChatRequest):
    """å¤„ç†æ‰€æœ‰èŠå¤©ã€åŠ¨ä½œå’Œæ–‡æ¡£ç”Ÿæˆè¯·æ±‚"""
    session = get_or_create_session(req.session_id)
    response_message = ""
    response_options = []
    
    if req.action == "associate_template":
        data = req.data or {}
        doc_id = data.get("doc_id")
        template_path = data.get("template_path")
        doc_item = session.document_items.get(doc_id)

        if not doc_item or not template_path:
            raise HTTPException(status_code=400, detail="Document item and template path are required.")
        
        doc_item.matched_template_path = template_path
        response_message = f"âœ… æ¨¡æ¿å·²æˆåŠŸå…³è”åˆ°é¡¹ç›® '{doc_item.name}'ã€‚"

    elif req.action == "reset_item":
        data = req.data or {}
        doc_id = data.get("doc_id")
        doc_item = session.document_items.get(doc_id)

        if not doc_item:
            raise HTTPException(status_code=404, detail="Document item not found.")
        
        # Reset the item's state
        doc_item.status = "å¾…å¤„ç†"
        doc_item.filled_document_path = None
        doc_item.error_info = None
        doc_item.matched_template_path = None
        
        logger.info(f"ğŸ”„ Item '{doc_item.name}' ({doc_id}) has been reset.")
        response_message = f"é¡¹ç›® '{doc_item.name}' å·²é‡ç½®ã€‚"

    elif req.message == 'ä½ å¥½':
        response_message = "æ‚¨å¥½ï¼æˆ‘æ˜¯AIæ–‡æ¡£ç”ŸæˆåŠ©æ‰‹ã€‚è¯·ä»ä¸‹æ–¹é€‰æ‹©æ‚¨è¦ä¸Šä¼ çš„å†…å®¹ç±»å‹ï¼Œæˆ–ç›´æ¥åœ¨èŠå¤©æ¡†ä¸­å‘æˆ‘æé—®ã€‚"
        response_options = [
            {"text": "é¡¹ç›®ç«£å·¥æ¸…å•", "action": "upload_completion_list", "message_id": "init_1"},
            {"text": "å¤šä¸ªæ¨¡æ¿", "action": "upload_templates", "message_id": "init_2"},
        ]
    else:
        response_message = f"æˆ‘æ”¶åˆ°äº†æ‚¨çš„æ¶ˆæ¯: '{req.message}'. ç›®å‰é€šç”¨èŠå¤©åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ã€‚"

    return JSONResponse({
        "message": response_message,
        "options": response_options,
        "dashboard": session.get_dashboard_data()
    })

@app.post("/api/upload")
async def upload_file_handler(
    session_id: str = Form(...),
    upload_type: str = Form(...),
    doc_id: Optional[str] = Form(None),
    file: UploadFile = File(...)
):
    """æ–‡ä»¶ä¸Šä¼ å¤„ç†"""
    session = get_or_create_session(session_id)
    
    # Create session-specific upload directory
    upload_dir = get_session_upload_dir(session_id)
    
    file_path = upload_dir / file.filename
    with open(file_path, "wb") as buffer:
        content = await file.read()
        buffer.write(content)
        
    response_message = f"ä¸Šä¼ æ–‡ä»¶ '{file.filename}' å¤±è´¥ã€‚"
    try:
        if upload_type == "upload_item_template":
            if not doc_id:
                raise HTTPException(status_code=400, detail="doc_id is required for this upload type")
            response_message = await process_item_template(session, str(file_path), file.filename, doc_id)
        elif upload_type == "upload_completion_list":
            response_message = await process_completion_list(session, str(file_path), file.filename)
        elif upload_type == "upload_templates":
            response_message = await process_templates(session, str(file_path), file.filename)
        elif upload_type == "upload_filled_doc":
            if not doc_id:
                 raise HTTPException(status_code=400, detail="doc_id is required for uploading a filled doc")
            
            output_dir = Path("generated_docs")
            output_dir.mkdir(exist_ok=True)
            # Use a unique name to avoid overwrites
            new_filename = f"{Path(file.filename).stem}_{doc_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}{Path(file.filename).suffix}"
            saved_path = output_dir / new_filename
            
            # Since file is already saved in uploads, move it
            os.rename(file_path, saved_path)

            doc_item = session.document_items.get(doc_id)
            if doc_item:
                doc_item.status = "å·²å®Œæˆ"
                doc_item.matched_template_path = "Manually Uploaded" # Indicate manual override
                doc_item.filled_document_path = str(saved_path)
                response_message = f"âœ… å·²ä¸º '{doc_item.name}' ä¸Šä¼ å¹¶å½’æ¡£å·²å¡«å†™çš„æ–‡æ¡£ã€‚"
            else:
                response_message = f"âš ï¸ æ‰¾ä¸åˆ°IDä¸º {doc_id} çš„é¡¹ç›®ï¼Œä½†æ–‡ä»¶å·²ä¿å­˜ã€‚"

        else:
            response_message = f"æœªçŸ¥çš„ä¸Šä¼ ç±»å‹: {upload_type}"
    except Exception as e:
        logger.error(f"Error processing upload for type '{upload_type}': {e}", exc_info=True)
        response_message = f"å¤„ç†æ–‡ä»¶ '{file.filename}' æ—¶å‘ç”Ÿé”™è¯¯ã€‚"

    return JSONResponse({
        "message": response_message,
        "dashboard": session.get_dashboard_data(),
        "options": []
    })

@app.get("/api/download/{session_id}/{doc_id}")
async def download_generated_file(session_id: str, doc_id: str):
    """ä¸‹è½½å·²ç”Ÿæˆçš„æ–‡æ¡£"""
    session = get_or_create_session(session_id)
    doc_item = session.document_items.get(doc_id)

    if not doc_item or not doc_item.filled_document_path or not os.path.exists(doc_item.filled_document_path):
        raise HTTPException(status_code=404, detail="æ–‡ä»¶æœªæ‰¾åˆ°æˆ–å°šæœªç”Ÿæˆã€‚")

    return FileResponse(
        path=doc_item.filled_document_path,
        filename=os.path.basename(doc_item.filled_document_path),
        media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
    )

# --- File Processing Logic ---

async def process_item_template(session: ChatSession, file_path: str, filename: str, doc_id: str) -> str:
    """ä¸ºç‰¹å®šé¡¹ç›®å…³è”æ¨¡æ¿"""
    if not (filename.endswith(".doc") or filename.endswith(".docx")):
        return f"âŒ æ¨¡æ¿æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: '{filename}'ã€‚è¯·ä¸Šä¼  .doc æˆ– .docx æ–‡ä»¶ã€‚"
    
    doc_item = session.document_items.get(doc_id)
    if not doc_item:
        return f"âŒ æœªæ‰¾åˆ°é¡¹ç›®ID: {doc_id}"

    # å°†æ¨¡æ¿ä¿å­˜åˆ°å…±äº«çš„'templates'ç›®å½•ä¸­ï¼Œä»¥ç¡®ä¿å…¶å¯ç”¨
    template_dir = Path("templates")
    template_dir.mkdir(exist_ok=True)
    
    # ä¸ºé¿å…å‘½åå†²çªï¼Œå¯ä»¥åœ¨æ–‡ä»¶åä¸­åŠ å…¥doc_id
    new_filename = f"{Path(filename).stem}_{doc_id}{Path(filename).suffix}"
    target_path = template_dir / new_filename
    
    import shutil
    shutil.copy(file_path, target_path)

    # æ›´æ–°æ–‡æ¡£é¡¹ç›®
    doc_item.matched_template_path = str(target_path)
    
    # å°†å…¶ä¹Ÿæ·»åŠ åˆ°ä¼šè¯ä¸­çš„é€šç”¨æ¨¡æ¿åˆ—è¡¨ä¸­
    session.templates[new_filename] = str(target_path)

    return f"âœ… å·²ä¸ºé¡¹ç›® '{doc_item.name}' æˆåŠŸå…³è”æ¨¡æ¿ '{filename}'ã€‚"

async def process_completion_list(session: ChatSession, file_path: str, filename: str) -> str:
    """ä»æ¸…å•æ–‡ä»¶ä¸­æå–é¡¹ç›®å¹¶æ›´æ–°ä»ªè¡¨æ¿"""
    items = []
    try:
        if filename.endswith('.docx'):
            doc = Document(file_path)
            # Try to extract from tables first
            for table in doc.tables:
                for row in table.rows:
                    cell_text = " ".join(cell.text.strip() for cell in row.cells).strip()
                    if cell_text:
                        items.append(cell_text)
            # If no tables, extract from paragraphs
            if not items:
                for para in doc.paragraphs:
                    if para.text.strip():
                        items.append(para.text.strip())
        elif filename.endswith('.json'):
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                # Expecting a list of strings or a dict with an "items" key
                items = data if isinstance(data, list) else data.get("items", [])
        elif filename.endswith('.txt'):
            with open(file_path, 'r', encoding='utf-8') as f:
                items = [line.strip() for line in f if line.strip()]
        
        # Filter out duplicates and very short lines
        unique_items = sorted(list(set([item for item in items if len(item) > 2])))
        
        if not unique_items:
            return f"åœ¨ '{filename}' ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„é¡¹ç›®ã€‚"

        # Update session dashboard
        for item_name in unique_items:
            # Avoid adding duplicate names
            if not any(item.name == item_name for item in session.document_items.values()):
                doc_id = f"doc_{uuid.uuid4().hex[:8]}"
                session.document_items[doc_id] = DocumentItem(name=item_name, doc_id=doc_id)

        return f"âœ… æˆåŠŸå¤„ç†æ¸…å• '{filename}'ï¼Œæ‰¾åˆ°å¹¶æ›´æ–°äº† {len(unique_items)} ä¸ªå¾…åŠé¡¹ç›®ã€‚"
    except Exception as e:
        logger.error(f"Error processing completion list '{filename}': {e}", exc_info=True)
        return f"âŒ å¤„ç†æ¸…å• '{filename}' æ—¶å‡ºé”™ã€‚"

async def process_templates(session: ChatSession, file_path: str, filename: str) -> str:
    """å¤„ç†ä¸Šä¼ çš„æ¨¡æ¿æ–‡ä»¶"""
    if not (filename.endswith(".doc") or filename.endswith(".docx")):
        return f"âŒ æ¨¡æ¿æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ: '{filename}'ã€‚è¯·ä¸Šä¼  .doc æˆ– .docx æ–‡ä»¶ã€‚"
        
    # Store template path in session for later use
    session.templates[filename] = file_path
    
    # Also copy to the main 'templates' directory to make it available for all sessions
    # This is a design choice - templates are shared.
    default_template_dir = Path("templates")
    default_template_dir.mkdir(exist_ok=True)
    
    target_path = default_template_dir / filename
    if not target_path.exists():
        import shutil
        shutil.copy(file_path, target_path)
        return f"âœ… æ¨¡æ¿ '{filename}' å·²æˆåŠŸä¸Šä¼ å¹¶å¯ä¾›ä½¿ç”¨ã€‚"
    else:
        return f"â„¹ï¸ æ¨¡æ¿ '{filename}' å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤ä¸Šä¼ ã€‚"

# --- Main Execution ---
if __name__ == '__main__':
    logger.info("ğŸš€ å¯åŠ¨AIæ–‡æ¡£ç”Ÿæˆå™¨Webåº”ç”¨...")
    # It's recommended to run with Uvicorn directly for more control
    # Example: uvicorn app:app --host 0.0.0.0 --port 8000 --reload
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True) 